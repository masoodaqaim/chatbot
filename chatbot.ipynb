{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning how to build a chatbox. Following Tech with Time (https://www.youtube.com/watch?v=wypVcNIH6D4&list=PLzMcBGfZo4-ndH9FoC4YWHGXG5RZekt-Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraies\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intent file is formated as a JSON file. Here is the format:\n",
    "{\"intents\": [\n",
    "        {\"tag\": \"greating\",\n",
    "        \"patterns\": [\"Hi\"],\n",
    "        \"response\" [\"Hello\"],\n",
    "        \"context_set\": \"\"\n",
    "        }\n",
    "        \n",
    "The basic structor is as follows:\n",
    "    - person types a message\n",
    "    - the chatbot, through deeplearning, tags the message\n",
    "    - the chatbot then returns with one of the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading our json file\n",
    "with open ('learning_nlp.json') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "#print(data)  # just to make sure we correctly loaded/read our file\n",
    "#print(data['intents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save each patten/grouping into a variable \n",
    "words = []\n",
    "labels = []\n",
    "docs_x = [] # for each patten, we need to know what intent is\n",
    "docs_y = [] \n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        # stemming will break each word in our pattern and break it down into the root word\n",
    "        # ex. \"Is anyone there?\": the root is \"there\" ignoreing the other words and ?\n",
    "        # we need to tokkenize (getting all the words)\n",
    "        wrds = nltk.word_tokenize(pattern)\n",
    "        words.extend(wrds)\n",
    "        docs_x.append(wrds)\n",
    "        docs_y.append(intent['tag'])\n",
    "        \n",
    "    if intent['tag'] not in labels:\n",
    "            labels.append(intent['tag'])\n",
    "            \n",
    "\n",
    "# stem all words and remove duplicates \n",
    "words = [stemmer.stem(w.lower()) for w in words if w != '?']\n",
    "words = sorted(list(set(words))) # set removes duplicates, list converts set back to list, sorted just sorts the words\n",
    "\n",
    "labels = sorted(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run data in a neural network, I need to convert the string data into numbers. To do this, I'll convert the strings into a \"bag of words\" (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []  # a list of 0 and 1. ex. [0,0,0,1,2,0,4,0] meaning there is 0 mention of 'a', 2 mention of \"hi\", etc\n",
    "output = []  # a list of 0 and 1. ex. [0,0,0,1] meaning there is a mention of \"goodby\"\n",
    "\n",
    "out_empty = [0 for _ in range(len(labels))]\n",
    "\n",
    "for x, doc in enumerate(docs_x):\n",
    "    bag = []\n",
    "    \n",
    "    wrds = [stemmer.stem(w) for w in doc]\n",
    "    \n",
    "    # one-hot encoding\n",
    "    for w in words:\n",
    "        if w in wrds: \n",
    "            bag.append(1)\n",
    "        else:\n",
    "            bag.append(0)\n",
    "            \n",
    "    output_row = out_empty[:]\n",
    "    output_row[labels.index(docs_y[x])] = 1  # look through the \"label\" list. See where the tag is in the list and place a 1\n",
    "\n",
    "    training.append(bag)\n",
    "    output.append(output_row)  # this is where i made the mistake. I coded: bag.append(output_row), should be ouput.app...\n",
    "    \n",
    "    \n",
    "training = np.array(training)\n",
    "output = np.array(output)\n",
    "\n",
    "# saving our data as a pickle file (used for serializing and de-serializing a Python object structure)\n",
    "with open('data_to_train.pickle', 'wb') as f:\n",
    "    pickle.dump((words, labels, training, output), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0]\n",
      "26\n",
      "26\n",
      "46\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# verify if training and output are correctly one-hot encoded\n",
    "\n",
    "test = 25\n",
    "\n",
    "print(training[test])\n",
    "print(output[test])\n",
    "\n",
    "print(len(training))\n",
    "print(len(output))\n",
    "\n",
    "print(len(training[test]))\n",
    "print(len(output[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# model layers\n",
    "net = tflearn.input_data(shape=[None, len(training[0])]) # the shape of data\n",
    "net = tflearn.fully_connected(net, 8) # hidden layer\n",
    "net = tflearn.fully_connected(net, 8) # hidden layer\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation='softmax') # probability distribution \n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net) # the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3999  | total loss: \u001b[1m\u001b[32m0.27194\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 1000 | loss: 0.27194 - acc: 0.9750 -- iter: 24/26\n",
      "Training Step: 4000  | total loss: \u001b[1m\u001b[32m0.24806\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 1000 | loss: 0.24806 - acc: 0.9775 -- iter: 26/26\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "model.save('model.tflearn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model accuracy: 98%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to create our function to store our words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(s, words):  # takes in a list of words\n",
    "    bag = [0 for _ in range(len(words))]  # creates an element of bag_of_words and chooses the element if the word exist\n",
    "    \n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "    \n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1  # 1 means word exist\n",
    "                #bag[i].append(1) # error: 'int' object has no attribute 'append' \n",
    "        \n",
    "        return np.array(bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to actually have the user \"talk\" to the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print('Start chatting (type \"quit\" to stop)')\n",
    "    while True:\n",
    "        u_input = input('You: ')\n",
    "        if u_input.lower() == 'quit':  # to exit the chat\n",
    "            break\n",
    "        \n",
    "    # take input, turn it into a bag of words, feed it to the model, model returns response\n",
    "        results = model.predict([bag_of_words(u_input, words)])  # eventhough we only have one prediction, you have to \n",
    "                                                             # feed in a list as predict expects a bunch of entries \n",
    "                                                             # to return a bunch of entries\n",
    "        #print(results) # returns a probability of what the model thinks should be the correct result\n",
    "        results_index = np.argmax(results) # this will return the index with the greatest value in our list of results\n",
    "        tag = labels[results_index]\n",
    "        #print(tag)\n",
    "        \n",
    "        # the code for the actual response\n",
    "        for tag_int in data['intents']:  # looking in our JSON file in the intents lable. data is our JSON file\n",
    "            if tag_int['tag'] == tag:  # if the tag_int matches the tag\n",
    "                responses = tag_int['responses']  # store the responese in the JSON file to responses variable\n",
    "        #print(random.choice(responses))\n",
    "        top_response = np.argmax(responses)\n",
    "        print(responses)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting (type \"quit\" to stop)\n",
      "You: helo\n",
      "[[0.05419211 0.30227187 0.5946966  0.00530772 0.03586594 0.00766577]]\n",
      "You: quite\n",
      "[[0.05419211 0.30227187 0.5946966  0.00530772 0.03586594 0.00766577]]\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "# without argmax\n",
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from above, the model returned 7 possible responses for 'hello' each with its own probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting (type \"quit\" to stop)\n",
      "You: hello\n",
      "greeting\n",
      "You: name\n",
      "name\n",
      "You: name\n",
      "name\n",
      "You: what is your name\n",
      "greeting\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "# with argmax, printing out the tag\n",
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we now get an actual word. This only prints the 'tag', not the response yet. The 'tag' is what the model thinks the root word is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting (type \"quit\" to stop)\n",
      "You: hello\n",
      "Hello!\n",
      "You: menu\n",
      "I am 30 years old!\n",
      "You: goodby\n",
      "Hope to see speak again!\n",
      "You: menu\n",
      "30 years young!\n",
      "You: name\n",
      "I'm cupcake bot!\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "# with a response code\n",
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chat() now prints the correct response. Still needs a bit of work as 'menu' returned '30 years young!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
